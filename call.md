---
layout: page
title: call
---
# Workshop description
Computational methods in semantics and pragmatics have recently gained in merit and popularity. One of the reasons for increased interest in modeling is its usefulness in operationalizing abstract predictions of formal semantics and pragmatics theories and linking them with experimental data, yielding not only a good fit to empirical data but also insights of theoretical relevance. Different modeling frameworks have been proposed to explain various aspects of linguistic data. On the one hand, some computational models propose domain-general, unified computational-level (in the sense of Marr, 1982) characterizations of meaning-related processes in order to rationalize how speakers and listeners utilize language in communication. On the other hand, procedural models describe language processing as the execution of series of steps that speakers and listeners carry out during language processing to compute utterance meanings. Both of these approaches have specific strengths and weaknesses but they also have the potential to complement each other.

In the field of experimental pragmatics, information theoretical and Bayesian models received much attention as they excel in capturing the dynamic interactions between speakers and listeners. Iterated response models (such as RSA, Frank & Goodman, 2012; or Franke, 2009), in particular, are able to explain linguistic phenomena at the semantics-pragmatics interface (e.g., scalar implicature computation), or effects of discourse and sociolinguistic factors (e.g., Questions Under Discussion or politeness; see Scontras, Tessler, & Franke, 2018, for review). These models provide an abstract explanation of how humans compute meaning but leave unspecified how this computation unfolds over time.

Procedural models, by contrast, zoom in on the algorithms (in the sense of Marr’s, 1982, second level) underlying meaning computation and propose sequences of processing steps, potentially executed via different modules. For example, in the domain of experimental semantics, procedural models (e.g. Szymanik, 2016; Bott, Schlotterbeck & Klein, 2019) were applied to quantifier interpretation and cognitive architectures such as ACT-R (Anderson, 2007) can capture a broad range of complex linguistic processes (Brasoveanu & Dotlacil, 2019).

# Call for abstracts

The goal of this workshop is to bring together researchers applying different modeling methodologies. We invite submissions that present state-of-the-art applications of computational and procedural models or discuss strengths and limitations of each of the mentioned methodologies. Moreover, because we see great potential for integrated computational and procedural models, we strongly encourage submissions that propose hybrid approaches. Such hybrid approaches may, for example, include sequential sampling decision models (e.g. Schlotterbeck et al., 2020; Ramotowska et al., 2023) or models of incremental interpretation (e.g. Cohn-Gorden et al., 2019; Waldon & Degen, 2021) as procedural extensions of Bayesian approaches. 

**Topics of interest include (but are not limited to):**
- procedural and/or computational models of incremental interpretation,
- procedural and/or computational models of language comprehension and production, 
- procedural and/or computational models of verification or inferences,
- behavioral and neurocognitive procedural and/or computational models,
- procedural and/or computational models of the semantics-pragmatics interface,
- procedural and/or computational models of context effects (e.g., politeness, conversation goals, informativeness) on interpretation, and
- procedural and/or computational models of interaction between language-specific and domain-general interpretation mechanisms.
 
**Submissions guidelines:**
Abstracts should be anonymous and not exceed 2 pages (plus one extra page for figures, tables, glosses, references, etc.) with 11 pt font size. Submissions can be made at the [workshop's EasyChair site](ttps://easychair.org/conferences/?conf=proscomps2023). 

